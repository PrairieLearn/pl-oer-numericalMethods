{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import numpy.linalg as la\n",
        "\n",
        "import scipy.optimize as sopt\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import axes3d\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Numerical Optimization "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Example of a constrained optimization problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suppose we want to maximize the area of a rectangle with sides `d1` and `d2`. \n",
        "\n",
        "We store these design variables in the array `x = np.array([d1,d2])`.\n",
        "\n",
        "We add to this problem a constraint that the perimeter should be less than a given quantity. The functions below evaluate the area and perimeter for input variable `x`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def A(x):\n",
        "    d1 = x[0]\n",
        "    d2 = x[1]\n",
        "    return d1*d2\n",
        "\n",
        "\n",
        "def P(x):\n",
        "    d1 = x[0]\n",
        "    d2 = x[1]\n",
        "    return 2*(d1+d2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can visualize how the area and perimeter change with `x` using 3d plots:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.gca(projection=\"3d\")\n",
        "\n",
        "xmesh, ymesh = np.mgrid[0:10:100j,0:10:100j]\n",
        "AMesh = A(np.array([xmesh, ymesh]))\n",
        "ax.plot_surface(xmesh, ymesh, AMesh, cmap=plt.cm.winter, rstride=3, cstride=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig2 = plt.figure()\n",
        "ax = fig2.gca(projection=\"3d\")\n",
        "\n",
        "PMesh = P(np.array([xmesh, ymesh]))\n",
        "ax.plot_surface(xmesh, ymesh, PMesh,  cmap=plt.cm.autumn, rstride=3, cstride=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.axis(\"equal\")\n",
        "plt.grid()\n",
        "figc1 = plt.contour(xmesh, ymesh, AMesh, 20, cmap=plt.cm.winter)\n",
        "figc2 = plt.contour(xmesh, ymesh, PMesh, 10, colors='k')\n",
        "plt.clabel(figc2, inline=1, fontsize=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's say we want to solve:\n",
        "\n",
        "```html\n",
        "max A\n",
        "st  P <= 20\n",
        "```\n",
        "\n",
        "or to use with minimize function\n",
        "\n",
        "```html\n",
        "min f = -A\n",
        "st g = 20 - P >= 0\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Initial guess\n",
        "x0 = np.array([9,1])\n",
        "f = lambda x: -A(x) \n",
        "g = lambda x: 20 - P(x)\n",
        "minimize(f, x0, constraints=({'type': 'ineq', 'fun': lambda x: g(x)}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) 1D Optimization Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this activity, we will find the optimizer of functions in 1d using two iterative methods. For each one, you should be thinking about cost and convergence rate.\n",
        "\n",
        "The iterative methods below can be applied to more complex equations, but here we will use a simple polynomial function of the form:\n",
        "\n",
        "$$f(x) =  a x^4 + b x^3 + c x^2 + d x + e $$\n",
        "\n",
        "The code snippet below provides the values for the constants, and functions to evaluate $f(x)$, $f'(x)$ and $f''(x)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = 17.09\n",
        "b = 9.79\n",
        "c = 0.6317\n",
        "d = 0.9324\n",
        "e = 0.4565\n",
        "\n",
        "def f(x):\n",
        "    return a*x**4 + b*x**3 + c*x**2 + d*x + e\n",
        "\n",
        "def df(x):\n",
        "    return 4*a*x**3 + 3*b*x**2 + 2*c*x + d\n",
        "\n",
        "def d2f(x):\n",
        "    return 3*4*a*x**2 + 2*3*b*x + 2*c\n",
        "\n",
        "xmesh = np.linspace(-1, 0.5, 100)\n",
        "plt.ylim([-1, 3])\n",
        "plt.plot(xmesh, f(xmesh))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### a) Golden Section Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "tau = (np.sqrt(5)-1)/2\n",
        "\n",
        "a0 = -0.9 #-2\n",
        "b0 = -0.2 #1\n",
        "\n",
        "h_k = b0 - a0  \n",
        "\n",
        "x1 = a0 + (1-tau) * h_k\n",
        "x2 = a0 + tau * h_k\n",
        "print(x1,x2)\n",
        "f1 = f(x1)\n",
        "f2 = f(x2)\n",
        "\n",
        "errors = [np.abs(h_k)]\n",
        "count = 0\n",
        "\n",
        "while (count < 30 and np.abs(h_k) > 1e-6):\n",
        " \n",
        "    if  f1>f2:\n",
        "        a0 = x1\n",
        "        x1 = x2\n",
        "        f1 = f2\n",
        "        h_k = b0-a0\n",
        "        x2 = a0 + tau * h_k\n",
        "        f2 = f(x2)\n",
        "    else:\n",
        "        b0 = x2\n",
        "        x2 = x1\n",
        "        f2 = f1\n",
        "        h_k = b0-a0\n",
        "        x1 = a0 + (1-tau) * h_k\n",
        "        f1 = f(x1)        \n",
        "    errors.append(np.abs(h_k))  \n",
        "    \n",
        "    print(\"%10g \\t %10g \\t %12g %12g\" % (a0, b0, errors[-1], errors[-1]/errors[-2]))\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### b) Newton's method in 1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.ylim([-1, 3])\n",
        "plt.plot(xmesh, f(xmesh))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's fix an initial guess:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_exact = -0.4549"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfx = df(x)\n",
        "d2fx = d2f(x)\n",
        "\n",
        "# carry out the Newton step\n",
        "xnew = x - dfx / d2fx\n",
        "\n",
        "# plot approximate function\n",
        "plt.plot(xmesh, f(xmesh))\n",
        "plt.plot(xmesh, f(x) + dfx*(xmesh-x) + d2fx*(xmesh-x)**2/2)\n",
        "plt.plot(x, f(x), \"o\", color=\"red\")\n",
        "plt.plot(xnew, f(xnew), \"o\", color=\"green\")\n",
        "plt.ylim([-1, 3])\n",
        "\n",
        "# update\n",
        "x = xnew\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = -0.1 #0.2\n",
        "for i in range(30):\n",
        "    \n",
        "    dfx = df(x)\n",
        "    d2fx = d2f(x)\n",
        "    xnew = x - dfx / d2fx\n",
        "    if np.abs(xnew-x) < 1e-8:\n",
        "        break\n",
        "    print(\" %i %10g \" % (i,x) )\n",
        "    x = xnew    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### c) Using scipy library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import scipy.optimize as sopt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "sopt.minimize?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "x0 = 2\n",
        "sopt.minimize(f, x0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "sopt.golden(f,brack=(-8,2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) ND Optimization Methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We provide three example of functions. You will be able to observe difference convergence carachteristics among them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Function 1:\n",
        "$$ f(x,y) = 0.5 x^2 + 2.5 y^2 $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f1(x):\n",
        "    return 0.5*x[0]**2 + 2.5*x[1]**2\n",
        "\n",
        "def df1(x):\n",
        "    return np.array([x[0], 5*x[1]])\n",
        "\n",
        "def ddf1(x):\n",
        "    return np.array([\n",
        "                     [1,0],\n",
        "                     [0,5]\n",
        "                     ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Function 2:\n",
        "$$ f(x,y) = (x-1)^2 + (y-1)^2 $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f2(x):\n",
        "    return (x[0]-1)**2 + (x[1]-1)**2\n",
        "\n",
        "def df2(x):\n",
        "    return np.array([2*(x[0]-1),2*(x[1]-1) ])\n",
        "\n",
        "def ddf2(x):\n",
        "    return np.array([\n",
        "                     [2,0],\n",
        "                     [0,2]\n",
        "                     ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Function 3:\n",
        "$$ f(x,y) = 100 (y-x^2)^2 + (1-x)^2 $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f3(X):\n",
        "    x = X[0]\n",
        "    y = X[1]\n",
        "    val = 100.0 * (y - x**2)**2 + (1.0 - x)**2\n",
        "    return val\n",
        "\n",
        "def df3(X):\n",
        "    x = X[0]\n",
        "    y = X[1]\n",
        "    val1 = -400.0 * (y - x**2) * x - 2 * (1 - x)\n",
        "    val2 = 200.0 * (y - x**2)\n",
        "    return np.array([val1, val2])\n",
        "\n",
        "def ddf3(X):\n",
        "    x = X[0]\n",
        "    y = X[1]\n",
        "    val11 = -400.0 * (y - x**2) + 800.0 * x**2 + 2\n",
        "    val12 = -400.0 * x\n",
        "    val21 = -400.0 * x\n",
        "    val22 = 200.0\n",
        "    return np.array([[val11, val12], [val21, val22]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Helper functions for plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plotFunction(f, interval=(-2,2), levels=20, steps=None, fhist=None):\n",
        "    \n",
        "    a,b = interval\n",
        "    \n",
        "    xmesh, ymesh = np.mgrid[a:b:100j,a:b:100j]\n",
        "    fmesh = f(np.array([xmesh, ymesh]))\n",
        "    \n",
        "    \n",
        "    fig = plt.figure(figsize=(16,4))\n",
        "\n",
        "    ax = fig.add_subplot(131,projection=\"3d\")\n",
        "    ax.plot_surface(xmesh, ymesh, fmesh,cmap=plt.cm.coolwarm);\n",
        "    plt.title('3d plot of f(x,y)')\n",
        "\n",
        "    ax = fig.add_subplot(132)\n",
        "    ax.set_aspect('equal')\n",
        "    c = ax.contour(xmesh, ymesh, fmesh, levels=levels)\n",
        "\n",
        "    plt.title('2d countours of f(x,y)')\n",
        "    ax.clabel(c, inline=1, fontsize=10)\n",
        "    \n",
        "    if steps is not None:  \n",
        "        plt.plot(steps.T[0], steps.T[1], \"o-\", lw=3, ms=10)\n",
        "     \n",
        "    if fhist is not None:\n",
        "        ax = fig.add_subplot(133)\n",
        "        plt.semilogy(fhist, '-o')\n",
        "        plt.xlabel('iteration')\n",
        "        plt.ylabel('f')\n",
        "        plt.grid()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "plotFunction(f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "plotFunction(f2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "plotFunction(f3,levels=np.logspace(0,4,10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plotConvergence( steps, exact , r ):\n",
        "       \n",
        "    error = la.norm(np.array(steps) - np.array(exact),axis=1)\n",
        "    ratio = []\n",
        "    for k in range(len(error)-1):\n",
        "        ratio.append( error[k+1]/error[k]**r )\n",
        "\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "    plt.plot(ratio, \"o-\", lw=3, ms=10)\n",
        "    plt.ylim(0,2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### A) Steepest Descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def steepestDescent(f,df,x0,maxiter,tol,alpha = 0):\n",
        "\n",
        "    # Line search function\n",
        "    def f_line(alpha):\n",
        "        fnew = f(x + alpha*s)\n",
        "        return fnew\n",
        "    \n",
        "    steps = [x0]   \n",
        "    x = x0\n",
        "    fhist = [f(x)]\n",
        "    \n",
        "    # Steepest descent with line search\n",
        "    for i in range(maxiter):\n",
        "\n",
        "        # Get the gradient\n",
        "        s = -df(x)\n",
        "\n",
        "        # Learning rate:\n",
        "        if alpha == 0:\n",
        "            # Perform line search\n",
        "            alpha_opt = sopt.golden(f_line)\n",
        "        else:\n",
        "            alpha_opt = alpha\n",
        "\n",
        "        # Steepest descent update\n",
        "        xnew = x + alpha_opt * s\n",
        "\n",
        "        # Save optimized solution for plotting\n",
        "        steps.append(xnew)\n",
        "        \n",
        "        fhist.append(f(xnew))\n",
        "\n",
        "        # Check convergence\n",
        "        \n",
        "        if ( np.abs(fhist[-1] - fhist[-2]) < tol ):\n",
        "            break\n",
        "\n",
        "        x = xnew\n",
        "        \n",
        "    print('optimal solution is:', x)\n",
        "        \n",
        "    return steps, fhist, i   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initial guess\n",
        "x0 = np.array([2, 2./5])\n",
        "# Steepest descent\n",
        "steps, fhist, iterations = steepestDescent(f1,df1,x0,50,1e-6)\n",
        "print('converged in', iterations, 'iterations')\n",
        "# Plot convergence   \n",
        "plotFunction(f1,steps=np.array(steps),fhist=np.array(fhist))\n",
        "\n",
        "plotConvergence( steps, [0,0] , 1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initial guess\n",
        "x0 = np.array([-1.5, -1])\n",
        "# Steepest descent\n",
        "steps, fhist, iterations = steepestDescent(f2,df2,x0,50,1e-4)\n",
        "print('converged in', iterations, 'iterations')\n",
        "# Plot convergence   \n",
        "plotFunction(f2,steps=np.array(steps),fhist=np.array(fhist))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initial guess\n",
        "x0 = np.array([0, 1.75])\n",
        "# Steepest descent\n",
        "steps, fhist, iterations = steepestDescent(f3,df3,x0,1000,1e-6)\n",
        "print('converged in', iterations, 'iterations')\n",
        "# Plot convergence   \n",
        "plotFunction(f3,steps=np.array(steps),levels=np.logspace(0,4,8), fhist=np.array(fhist))\n",
        "\n",
        "plotConvergence( steps, [1 , 1] , 1 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initial guess\n",
        "x0 = np.array([-0.5, -1])\n",
        "# Steepest descent\n",
        "steps, fhist, iterations = steepestDescent(f3,df3,x0,1000,1e-6)\n",
        "print('converged in', iterations, 'iterations')\n",
        "# Plot convergence   \n",
        "plotFunction(f3,steps=np.array(steps),levels=np.logspace(0,4,8), fhist=np.array(fhist))\n",
        "\n",
        "plotConvergence( steps, [1 , 1] , 1 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### B) Newton's method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def NewtonMethod(f,df,ddf,x0,maxiter,tol):\n",
        "    \n",
        "    steps = [x0]   \n",
        "    x = x0\n",
        "    fhist = [f(x)]\n",
        "    \n",
        "    # Steepest descent with line search\n",
        "    for i in range(maxiter):\n",
        "\n",
        "        # Get the newton step\n",
        "        s = la.solve(ddf(x), -df(x))\n",
        "\n",
        "        # Steepest descent update\n",
        "        xnew = x + s\n",
        "\n",
        "        # Save optimized solution for plotting\n",
        "        steps.append(xnew)\n",
        "        \n",
        "        fhist.append(f(xnew))\n",
        "\n",
        "        # Check convergence\n",
        "        \n",
        "        if ( np.abs(fhist[-1] - fhist[-2]) < tol ):\n",
        "            break\n",
        "\n",
        "        x = xnew\n",
        "        \n",
        "    print('optimal solution is:', x)\n",
        "        \n",
        "    return steps, fhist, i "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initial guess\n",
        "x0 = np.array([2, 2./5])\n",
        "# Newton's method\n",
        "steps, fhist, iterations = NewtonMethod(f1,df1,ddf1,x0,50,1e-6)\n",
        "print('converged in', iterations, 'iterations')\n",
        "# Plot convergence   \n",
        "plotFunction(f1,steps=np.array(steps),fhist=np.array(fhist))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initial guess\n",
        "x0 = np.array([-1, -1.0])\n",
        "# Newton's method\n",
        "steps, fhist, iterations = NewtonMethod(f2,df2,ddf2,x0,50,1e-6)\n",
        "print('converged in', iterations, 'iterations')\n",
        "# Plot convergence   \n",
        "plotFunction(f2,steps=np.array(steps),fhist=np.array(fhist))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initial guess\n",
        "x0 = np.array([-0.5, -1])\n",
        "# Newton's method\n",
        "steps, fhist, iterations = NewtonMethod(f3,df3,ddf3,x0,50,1e-8)\n",
        "print('converged in', iterations, 'iterations')\n",
        "# Plot convergence   \n",
        "plotFunction(f3,steps=np.array(steps),levels=np.logspace(0,4,8), fhist=np.array(fhist))\n",
        "\n",
        "plotConvergence( steps, [1 , 1] , 2 )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}