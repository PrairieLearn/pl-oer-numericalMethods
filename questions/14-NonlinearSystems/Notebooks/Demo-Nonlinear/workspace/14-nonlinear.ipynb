{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import numpy.linalg as la\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set(font_scale=2)\n",
        "sns.set_style(\"whitegrid\")\n",
        "np.seterr(divide='ignore');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# A) One dimensional nonlinear equations\n",
        "\n",
        "## Example 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this activity, we will find the root of nonlinear equations using three different iterative methods. For each one, you should be thinking about cost and convergence rate.\n",
        "\n",
        "The iterative methods below can be applied to more complex equations, but here we will use a simple nonlinear equation of the form:\n",
        "\n",
        "$$f(x) = e^x - 2 $$\n",
        "\n",
        "The exact root that satisfies $f(x) = 0$ is $x = ln(2) \\approx 0.693147$. We can take a look at the function in the interval $[-2,2]$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a0 = -2\n",
        "b0 = 2\n",
        "\n",
        "x = np.linspace(a0, b0)\n",
        "\n",
        "def f(x):\n",
        "    return np.exp(x) - 2\n",
        "\n",
        "def df(x):\n",
        "    return np.exp(x)\n",
        "\n",
        "\n",
        "xtrue = np.log(2)\n",
        "\n",
        "plt.plot(x, f(x))\n",
        "plt.plot(xtrue,0,'ro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### a) Bisection Method\n",
        "\n",
        "#### First we will run the iterative process for a few iterations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = a0\n",
        "b = b0\n",
        "interval = np.abs(a - b)   \n",
        "errors = []\n",
        "\n",
        "fa = f(a)\n",
        "\n",
        "for i in range(12):\n",
        "    m = (a+b)/2\n",
        "    fm = f(m)   \n",
        "    if  np.sign(fa) == np.sign(fm):\n",
        "        a = m \n",
        "        fa = fm # this line is not really needed, \n",
        "        # since we only need the sign of a, and sign of a is the same as sign of m\n",
        "    else:\n",
        "        b = m\n",
        "    interval = np.abs(a - b)    \n",
        "    errors.append(interval)        \n",
        "    print(\"%10g \\t %10g \\t %12g\" % (a, b, interval))\n",
        "    \n",
        "print('exact root is = ', np.log(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Now we will add a stopping criteria. \n",
        "\n",
        "Since we know the interval gets divided by two every iteration, how many iterations do we need to perform to achieve the tolerance $2^{-k}$?\n",
        "\n",
        "Note that only one function evaluation is needed per iteration!\n",
        "\n",
        "We can also verify the linear convergence, with C = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = a0\n",
        "b = b0\n",
        "interval = np.abs(a - b)   \n",
        "errors = [interval]\n",
        "\n",
        "fa = f(a)\n",
        "count = 0\n",
        "\n",
        "while count < 30 and interval > 2**(-4):\n",
        "    m = (a+b)/2\n",
        "    fm = f(m)   \n",
        "    if  fa*fm > 0:\n",
        "        a = m \n",
        "    else:\n",
        "        b = m\n",
        "    interval = np.abs(a - b)    \n",
        "    errors.append(interval)        \n",
        "    print(\"%10g \\t %10g \\t %12g %12g\" % (a, b, interval, interval/errors[-2]))\n",
        "    \n",
        "print('exact root is = ', np.log(2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(errors)\n",
        "plt.ylabel('Error (interval size)')\n",
        "plt.xlabel('Iterations')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What happens if you have multiple roots inside the interval? Bisection method will converge to one of the roots. Try to run the code snippet above using the function \n",
        "\n",
        "$$ f(x) = 0.5 x^2 - 2 $$\n",
        "\n",
        "Change the interval, and observe what happens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true
      },
      "source": [
        "### b) Newton's Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x0 = 2\n",
        "r = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = x0\n",
        "count = 0\n",
        "tol = 1e-6\n",
        "err = 1\n",
        "errors = [err]\n",
        "\n",
        "while count < 30 and err > tol:\n",
        "    x = x - f(x)/df(x)\n",
        "    err = abs(x-xtrue)\n",
        "    errors.append(err)\n",
        "    print('%10g \\t%10g \\t %.16e %.4g' % (x, f(x), err, errors[-1]/(errors[-2]**r) ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### c) Secant Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x0 = 2\n",
        "x1 = 8\n",
        "r = 2\n",
        "#r = 1.618"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Need two initial guesses\n",
        "xbefore = x0\n",
        "x = x1\n",
        "count = 0\n",
        "tol = 1e-8\n",
        "err = 1\n",
        "errors = [err]\n",
        "\n",
        "while count < 30 and err > tol:\n",
        "\n",
        "    df_approx = (f(x)-f(xbefore))/(x-xbefore)\n",
        "    xbefore = x\n",
        "    x = x - f(x)/df_approx\n",
        "    err = abs(x-xtrue)\n",
        "    errors.append(err)\n",
        "    print('%10g \\t%10g \\t %.16e %.4g' % (x, f(x), err, errors[-1]/errors[-2]**r ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### d) Using scipy functions for root finding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import scipy.optimize as opt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "opt.root_scalar(f,bracket=[-2, 3],method='bisect')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "opt.root_scalar(f,bracket=[-2, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "opt.root_scalar(f,x0=3, fprime=df, method='newton')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "opt.root_scalar(f,x0=3,x1=4, method='secant')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 2)\n",
        "\n",
        "### a) Graphical convergence of Newton's Method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's take a look at this other function\n",
        "\n",
        "$$f(x) = x^3 - x + 1 $$\n",
        "\n",
        "And we plot it in the interval $[-4,4]$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f(x):\n",
        "    return x**3 - x +1\n",
        "\n",
        "def df(x):\n",
        "    return 3*x**2 - 1\n",
        "\n",
        "xmesh = np.linspace(-4, 4, 100)\n",
        "plt.ylim([-5, 10])\n",
        "plt.plot(xmesh, f(xmesh))\n",
        "\n",
        "xexact = -1.324717957244746\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "guesses = [-.9]\n",
        "guesses = [1.5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate this cell many times in-place (using Ctrl-Enter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = guesses[-1] # grab last guess\n",
        "\n",
        "slope = df(x)\n",
        "\n",
        "# plot approximate function\n",
        "plt.plot(xmesh, f(xmesh))\n",
        "plt.plot(xmesh, f(x) + slope*(xmesh-x))\n",
        "plt.plot(x, f(x), \"o\")\n",
        "plt.xlim([-4, 4])\n",
        "plt.ylim([-5, 10])\n",
        "plt.axhline(0, color=\"black\")\n",
        "\n",
        "# Compute approximate root\n",
        "xnew = x - f(x) / slope\n",
        "guesses.append(xnew)\n",
        "print(xnew)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "f(xnew)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(guesses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "error = abs(np.array(guesses)-xexact)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "plt.semilogy(error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### b) Graphical convergence of Secant Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "guesses = [2, 1.7]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate this cell many times in-place (using Ctrl-Enter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# grab last two guesses\n",
        "x = guesses[-1]\n",
        "xbefore = guesses[-2]\n",
        "\n",
        "slope = (f(x)-f(xbefore))/(x-xbefore)\n",
        "\n",
        "# plot approximate function\n",
        "plt.plot(xmesh, f(xmesh))\n",
        "plt.plot(xmesh, f(x) + slope*(xmesh-x))\n",
        "plt.plot(x, f(x), \"o\")\n",
        "plt.plot(xbefore, f(xbefore), \"o\")\n",
        "plt.ylim([-4, 4])\n",
        "plt.ylim([-3, 10])\n",
        "plt.axhline(0, color=\"black\")\n",
        "\n",
        "# Compute approximate root\n",
        "xnew = x - f(x) / slope\n",
        "guesses.append(xnew)\n",
        "print(xnew)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# B) N-Dimensional Nonlinear Equations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will solve the following system of nonlinear equations:\n",
        "\n",
        "$$ x + 2y = 2 $$\n",
        "\n",
        "$$ x^2 + 4y^2 = 4 $$\n",
        "\n",
        "We will define our vector valued function ${\\bf f}$, which takes a vector as argument, with the components $x$ and $y$. We are trying to find the numerical (approximated) solution that safisfies:\n",
        "\n",
        "$${\\bf f} = \\begin{bmatrix} f_1 \\\\ f_2 \\end{bmatrix}\n",
        "          = \\begin{bmatrix} x + 2y - 2 \\\\ x^2 + 4y^2 - 4 \\end{bmatrix}\n",
        "          = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$$\n",
        "          \n",
        "and the exact solution is $[0,1]$\n",
        "\n",
        "We will also define the gradient of ${\\bf f}$, $\\nabla{\\bf f}$, which we call the Jacobian."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Newton's method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def f(xvec):\n",
        "    x, y = xvec\n",
        "    return np.array([\n",
        "        x + 2*y -2,\n",
        "        x**2 + 4*y**2 - 4\n",
        "        ])\n",
        "\n",
        "def Jf(xvec):\n",
        "    x, y = xvec\n",
        "    return np.array([\n",
        "        [1, 2],\n",
        "        [2*x, 8*y]\n",
        "        ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pick an initial guess."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.array([1, 2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now implement Newton's method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    s = la.solve(Jf(x), -f(x))\n",
        "    x = x + s\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check if that's really a solution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "f(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The cost is $O(n^3)$ per iteration, since the Jacobian changes every iteration. But how fast is the convergence?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "r = 2\n",
        "\n",
        "xtrue = np.array([0, 1])\n",
        "x = np.array([1, 2])\n",
        "errors = [la.norm(x)]\n",
        "\n",
        "while errors[-1] > 1e-12:\n",
        "    A = Jf(x)\n",
        "    s = la.solve(A, f(x))\n",
        "    x = x - s\n",
        "    err = la.norm(x-xtrue)\n",
        "    errors.append(err)\n",
        "    print(' %.16e \\t %.4g' % (err, errors[-1]/errors[-2]**r ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Finite Difference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Suppose you don't know how to calculate the Jacobian. You can use Forward Finite Difference to approximate the derivatives! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fd(xvec,dx):\n",
        "    fval = f(xvec)\n",
        "    J = np.zeros((fval.shape[0],xvec.shape[0]))\n",
        "    for j in range(len(xvec)):\n",
        "        xvec[j] = xvec[j] + dx\n",
        "        dfd = f(xvec)-fval\n",
        "        for i in range(len(fval)):\n",
        "            J[i,j] = dfd[i]/dx\n",
        "        xvec[j] = xvec[j] - dx\n",
        "    return J"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.array([4, 2],dtype=float)\n",
        "fd(x,0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "Jf(np.array([4,2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = np.array([1., 2])\n",
        "for i in range(10):\n",
        "    s = la.solve(fd(x,0.0001), -f(x))   \n",
        "    x = x + s\n",
        "    print(x)\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# C) Inverse Kinematics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import numpy.linalg as la\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from scipy.optimize import fsolve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The helper functions below will be used for plotting purposes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# helper functions for plotting\n",
        "\n",
        "def endpt(pt, ang, length):\n",
        "    x, y = pt\n",
        "    endy = y + length * np.sin(ang)\n",
        "    endx = x + length * np.cos(ang)\n",
        "    return endx, endy\n",
        "\n",
        "def plotarms(x,y,beta,a,b,sol):\n",
        "\n",
        "    fig = plt.figure(figsize = (12,6))\n",
        "\n",
        "    startx, starty = (0,0)\n",
        "    endx, endy = endpt((startx,starty),sol[0],a)\n",
        "    plt.plot([startx, endx], [starty, endy], '-r', linewidth=4)\n",
        "    plt.plot([startx], [starty], 'ko',markersize=12)\n",
        "    plt.plot([endx], [endy], 'ko',markersize=12)\n",
        "    plt.text(startx-0.3, starty+0.3, r'$A$', fontsize=20)\n",
        "    plt.text(endx, endy+0.3, r'$B$', fontsize=20)\n",
        "    plt.text(startx+0.8, starty, r'$\\theta_1$', fontsize=20)\n",
        "    plt.plot([endx, x], [endy, y], '-g', linewidth=4)\n",
        "    plt.plot([x], [y], 'ko',markersize=12)\n",
        "    plt.text(x, y-1, r'$C$', fontsize=20)\n",
        "    plt.text(endx-0.5, endy-1.2, r'$\\theta_2$', fontsize=20)\n",
        "    plt.text(x-0.2, y+0.5, r'$\\theta_3$', fontsize=20)\n",
        "    plt.plot([x, x+2], [y, y], '--k')\n",
        "    plt.plot([x, x+2*np.cos(beta)], [y, y+2*np.sin(beta)], '--k')\n",
        "    plt.text(x+np.cos(beta), y, r'$\\beta$', fontsize=20)\n",
        "\n",
        "    plt.xlim(-1,a+b)\n",
        "    plt.ylim(-1,0.8*a)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You have derived the equations needed to solve this inverse kinematics problem. Below is the implementation of the function and its derivative (the Jacobian):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def func(xvec, *args):   \n",
        "    #xvec = (theta1, theta2, theta3)   \n",
        "    a,b,x,y,beta  = args\n",
        "    \n",
        "    c      = np.sqrt(x**2 + y**2)    \n",
        "    alpha2 = np.arcsin(y/c)\n",
        "    \n",
        "    f = np.zeros(3)\n",
        "    \n",
        "    f[0] = a**2 + b**2 - 2*a*b*np.cos(xvec[1]) - c**2    \n",
        "    f[1] = a**2 + c**2 - 2*a*c*np.cos(xvec[0] - alpha2) - b**2\n",
        "    f[2] = xvec[0] + xvec[1]- xvec[2] - beta\n",
        "    \n",
        "    return f\n",
        "\n",
        "def dfunc(xvec, *args):\n",
        "    # A function to compute the Jacobian of func with derivatives across the rows.      \n",
        "    #xvec = (theta1, theta2, theta3)\n",
        "    a,b,x,y,beta  = args\n",
        "      \n",
        "    c      = np.sqrt(x**2 + y**2)    \n",
        "    alpha2 = np.arcsin(y/c)\n",
        "    \n",
        "    df = np.zeros((3,3))\n",
        "    \n",
        "    df[0,0] = 0\n",
        "    df[0,1] = 2*a*b*np.sin(xvec[1])   \n",
        "    df[0,2] = 0\n",
        "    \n",
        "    df[1,0] = 2*a*c*np.sin(xvec[0] - alpha2) \n",
        "    df[1,1] = 0  \n",
        "    df[1,2] = 0\n",
        "\n",
        "    df[2,0] = 1\n",
        "    df[2,1] = 1 \n",
        "    df[2,2] = -1\n",
        "    \n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Given** the desire position of the robotic hand:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = 8\n",
        "y = 2\n",
        "beta = np.pi/4\n",
        "\n",
        "c = np.sqrt(x**2+y**2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and variables corresponding to the geometry of the robotic arm:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Given arm lengths:\n",
        "a = 10\n",
        "b = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can **find** the angles for the joints, or the angles $\\theta_1, \\theta_2, \\theta_3$. Since the solution of nonlinear system of equations requires an iterative process, we need to provide initial values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set initial guess\n",
        "theta1guess = np.pi/2\n",
        "theta2guess = np.arccos( (a**2+b**2-c**2)/(2*a*b) )\n",
        "theta3guess = theta1guess+theta2guess\n",
        "x0 = [theta1guess,theta2guess,theta3guess]\n",
        "print(np.degrees(x0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will use the python function:\n",
        "    \n",
        "[https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fsolve.html  ](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fsolve.html) \n",
        "\n",
        "to solve this nonlinear problem. \n",
        "\n",
        "The `fsolve` function requires `func`, which is the function that evaluates ${\\bf f(x)}$, and the initial guess `x0`.\n",
        "\n",
        "```python\n",
        "scipy.optimize.fsolve(func, x0, args=(), fprime=None)\n",
        "```\n",
        "\n",
        "You can also set `args` to pass additional parameters. If you only provide `func`, `fsolve` will approximate the Jacobian. However, you can provide a function to compute the Jacobian as `fprime`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will create a variable to store the \"optional\" parameters to be used as arguments of the \"fsolve\" function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create tuple with optional problem parameters\n",
        "const = (a,b,x,y,beta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Solve for the unknowns using fsolve (only function provided)\n",
        "# sol = [theta1, theta2, theta3]\n",
        "(sol,info,ier,msg) = fsolve(func, x0, const, full_output=True)\n",
        "print(np.degrees(sol))\n",
        "print('number of function evaluations = ', info['nfev'])\n",
        "plotarms(x,y,beta,a,b,sol)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Solve for the unknowns using fsolve  (function and jacobian provided)\n",
        "# sol = [theta1, theta2, theta3]\n",
        "(sol,info,ier,msg) = fsolve(func, x0, args=const, full_output=True, fprime = dfunc)\n",
        "print(np.degrees(sol))\n",
        "print('number of function evaluations = ', info['nfev'])\n",
        "print('number of jacobian evaluations = ', info['njev'])\n",
        "plotarms(x,y,beta,a,b,sol)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that both methods yield the same result, however, when the jacobian is provided, the method requires less function evaluations. \n",
        "\n",
        "You can also obtain the solution implementing your own Newton method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Implementing Newton Method\n",
        "x = np.random.uniform(low=np.pi/10, high=np.pi/2, size=(3,))\n",
        "er = 1\n",
        "count = 0\n",
        "while er > 1e-9 and count < 100:\n",
        "    count += 1\n",
        "    h = la.solve(dfunc(x,*const), func(x,*const))\n",
        "    x = x - h\n",
        "    er = la.norm(h)\n",
        "print('number of function evaluations = ', count)\n",
        "print(np.degrees(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}